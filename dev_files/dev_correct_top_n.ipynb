{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "import copy\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, original_dataset, metrics, k_values):\n",
    "        self.dataset = copy.deepcopy(original_dataset)\n",
    "        self.metrics = metrics\n",
    "        self.k_values = [int(k) for k in k_values]\n",
    "\n",
    "    def evaluate(self, model, eval_dataset, model_dataset):\n",
    "        results = {}\n",
    "        for metric in self.metrics:\n",
    "            if metric == \"R2_model\":\n",
    "                results[metric] = self.r2_model(model, eval_dataset)\n",
    "            else:\n",
    "                for k in self.k_values:\n",
    "                    if metric == \"top-k\":\n",
    "                        results[f\"top-{k} model\"] = self.top_n_correct(k, model)\n",
    "                    elif metric == \"R2_k\":\n",
    "                        results[f\"R2_k-{k}\"] = self.r2_n(k, model)\n",
    "                    elif metric == \"top-k-acquired\":\n",
    "                        results[f\"top-{k} acquired\"] = self.top_n_in_model_set(k, model_dataset)\n",
    "        return results\n",
    "\n",
    "    def top_n_correct(self, n, model):\n",
    "        model_predictions = model.predict(self.dataset) # Predict on the full dataset\n",
    "        preds_indices = np.argsort(model_predictions)[:n] # Sort all predictions from lowest to highest and gets the indices of n amount of mols\n",
    "        top_n_real_indices = np.argsort(self.dataset.y)[:n] # Get the indices of the n \"real\" mols and sorts them from lowest to highest\n",
    "        return np.mean(np.isin(preds_indices, top_n_real_indices)) # np.isin calculates how many from the correct_preds_indices that are in top_n_real_indices and np.mean makes this a fraction\n",
    "    \n",
    "    def top_n_in_model_set(self, n, model_dataset):\n",
    "        #print(\"n\", n)\n",
    "        print(\"model_dataset\", model_dataset)\n",
    "        lowest_y_indices = np.argsort(self.dataset.y)[:n]  # Get indices of the 'n' lowest y values.\n",
    "        #print(\"lowest_y_indices len\", len(lowest_y_indices))\n",
    "        #print(\"lowest_y_indices\", lowest_y_indices)\n",
    "        lowest_y_ids = set(self.dataset.ids[lowest_y_indices])  # Retrieve corresponding IDs from the dataset and ensure uniqueness.\n",
    "        #print(\"lowest_y_ids\", lowest_y_ids)\n",
    "        #print(\"lowest_y_ids len\", len(lowest_y_ids))\n",
    "\n",
    "        ids_acquired = set(model_dataset.ids)  # Retrieve unique ids from the internal model dataset.\n",
    "        # print(\"ids_acquired:\", ids_acquired)\n",
    "        intersection_count = len(lowest_y_ids.intersection(ids_acquired))  # Count of common ids between lowest_y_ids and ids_acquired.\n",
    "        \n",
    "        return intersection_count / n  # Return the proportion of top 'n' found in the model_dataset.\n",
    "    \n",
    "    # def top_n_in_model_set(self, n, model_dataset):\n",
    "    #     lowest_y_indices = np.argsort(self.dataset.y)[:n]  # Get indices of the 'n' lowest y values.\n",
    "    #     lowest_y_ids = self.dataset.ids[lowest_y_indices]  # Retrieve corresponding IDs from the dataset.\n",
    "    #     ids_acquired = model_dataset.ids  # Retrieve ids from the internal model dataset.\n",
    "    #     mols_of_top_n_found = np.mean(np.isin(ids_acquired, lowest_y_ids))\n",
    "    #     return mols_of_top_n_found\n",
    "\n",
    "    \n",
    "\n",
    "    def r2_model(self, model, model_dataset):\n",
    "        '''\n",
    "        Returns the R2 value of the internal model\n",
    "        '''\n",
    "\n",
    "        # Find missing points in the model_dataset\n",
    "        training_points = self.dataset.missing_points(self.dataset, model_dataset)\n",
    "\n",
    "        y_true = training_points.y\n",
    "        y_pred = model.predict(training_points)\n",
    "\n",
    "        return r2_score(y_true, y_pred)\n",
    "    \n",
    "\n",
    "    def r2_n(self, n, model):\n",
    "        # Similar to top_n_correct but here we calculate the r2 score for the top n points\n",
    "        model_predictions = model.predict(self.dataset)\n",
    "        top_n_pred_indices = np.argsort(model_predictions)[:n]\n",
    "\n",
    "        # Get top n points as a Dataset\n",
    "        top_n_dataset = self.dataset.get_points(top_n_pred_indices)\n",
    "\n",
    "        y_pred = model.predict(top_n_dataset)\n",
    "        \n",
    "        return r2_score(top_n_dataset.y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dataset X.shape: (9898, 512), y.shape: (9898,), w.shape: (9898,), ids: ['C[C@@H](NC(=O)N1C[C@H](c2ccccc2)[C@H]2COCC[C@H]21)c1ccc(NC(=O)NC2CC2)cc1'\n",
       " 'O=C(Nc1cccc(C(=O)N2CCC(c3c[nH]c4ncccc34)CC2)c1)[C@@H]1Cc2ccccc2O1'\n",
       " 'Cc1nn(-c2ccccc2)c2nc(C(=O)N3CCC([C@H]4C(=O)Nc5ccccc54)CC3)ccc12' ...\n",
       " 'Cn1cccc(C(=O)N2CCN(C3CC3)c3ccc(Cl)cc32)c1=O'\n",
       " 'O=C([O-])[C@H]1CC[C@@H](C(=O)N2CCCc3ccccc32)CC1'\n",
       " 'CCNS(=O)(=O)c1cc(NCCOC)ccn1']>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import MDRMF as mf\n",
    "\n",
    "data = mf.MoleculeLoader(datafile=\"10K.csv\", smi_col=\"SMILES\", scores_col=\"r_i_docking_score\").df\n",
    "feat = mf.Featurizer(data)\n",
    "features = feat.featurize(\"morgan\", radius=2, nBits=512)\n",
    "\n",
    "X = features\n",
    "y = data['r_i_docking_score']\n",
    "ids = data['SMILES']\n",
    "\n",
    "dataset = mf.Dataset(X=X, y=y, ids=ids)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y values of starting points [-8.70208 -9.17715]\n",
      "model_dataset <Dataset X.shape: (4, 512), y.shape: (4,), w.shape: (4,), ids: ['CC(=O)N1Cc2ccc(NS(=O)(=O)c3cc(F)cc(Cl)c3)cc2C1'\n",
      " 'CN(c1ccccc1)C1CCN(C(=O)[C@@H]2CCNC(=O)C2)CC1'\n",
      " 'O=C1C[C@@H](C(=O)N2CC[C@@H](Cc3ccc(F)cc3)C2)CCN1'\n",
      " 'O=C1C[C@@H](C(=O)N2CC[C@H](Cc3ccc(F)cc3)C2)CCN1']>\n",
      "Iteration 1, Results: {'top-100 model': 0.01, 'top-100 acquired': 0.0}\n",
      "model_dataset <Dataset X.shape: (6, 512), y.shape: (6,), w.shape: (6,), ids: ['CC(=O)N1Cc2ccc(NS(=O)(=O)c3cc(F)cc(Cl)c3)cc2C1'\n",
      " 'CN(c1ccccc1)C1CCN(C(=O)[C@@H]2CCNC(=O)C2)CC1'\n",
      " 'O=C1C[C@@H](C(=O)N2CC[C@@H](Cc3ccc(F)cc3)C2)CCN1'\n",
      " 'O=C1C[C@@H](C(=O)N2CC[C@H](Cc3ccc(F)cc3)C2)CCN1'\n",
      " 'NC(=O)c1cccnc1N1CCN(C(=O)[C@@H]2CCNC(=O)C2)CC1'\n",
      " 'O=C1C[C@H](C(=O)N2CC[C@H](Cc3ccc(F)cc3)C2)CCN1']>\n",
      "Iteration 2, Results: {'top-100 model': 0.0, 'top-100 acquired': 0.0}\n",
      "model_dataset <Dataset X.shape: (8, 512), y.shape: (8,), w.shape: (8,), ids: ['CC(=O)N1Cc2ccc(NS(=O)(=O)c3cc(F)cc(Cl)c3)cc2C1'\n",
      " 'CN(c1ccccc1)C1CCN(C(=O)[C@@H]2CCNC(=O)C2)CC1'\n",
      " 'O=C1C[C@@H](C(=O)N2CC[C@@H](Cc3ccc(F)cc3)C2)CCN1'\n",
      " 'O=C1C[C@@H](C(=O)N2CC[C@H](Cc3ccc(F)cc3)C2)CCN1'\n",
      " 'NC(=O)c1cccnc1N1CCN(C(=O)[C@@H]2CCNC(=O)C2)CC1'\n",
      " 'O=C1C[C@H](C(=O)N2CC[C@H](Cc3ccc(F)cc3)C2)CCN1'\n",
      " 'CN1C(=O)c2ccc(C(=O)N3CCC(N(C)c4ccccc4)CC3)cc2C1=O'\n",
      " 'CN(C)c1cccc(C(=O)N[C@@H](CO)C(=O)[O-])c1']>\n",
      "Iteration 3, Results: {'top-100 model': 0.01, 'top-100 acquired': 0.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = ['top-k', 'top-k-acquired']\n",
    "k_values = ['100']\n",
    "eval = Evaluator(dataset, metrics, k_values)\n",
    "\n",
    "from MDRMF import models\n",
    "from MDRMF.models.rfmodeller import RFModeller\n",
    "\n",
    "rf_model = RFModeller(\n",
    "    dataset=dataset,\n",
    "    evaluator=eval,\n",
    "    iterations=3,\n",
    "    initial_sample_size=2,\n",
    "    acquisition_size=2,\n",
    "    acquisition_method=\"greedy\",\n",
    "    n_estimators=50\n",
    ")\n",
    "\n",
    "model = mf.Model(model=rf_model)\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
