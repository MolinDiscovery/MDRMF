{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from MDRMF.dataset import Dataset\n",
    "\n",
    "class ModellerDev:\n",
    "    \"\"\"\n",
    "    Base class to construct other models from\n",
    "    \n",
    "    Parameters:\n",
    "        dataset (Dataset): The dataset object containing the data.\n",
    "        evaluator (Evaluator): The evaluator object used to evaluate the model's performance.\n",
    "        iterations (int): The number of iterations to perform.\n",
    "        initial_sample_size (int): The number of initial samples to randomly select from the dataset.\n",
    "        acquisition_size (int): The number of points to acquire in each iteration.\n",
    "        acquisition_method (str): The acquisition method to use, either \"greedy\" or \"random\".\n",
    "        retrain (bool): Flag indicating whether to retrain the model in each iteration.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            dataset, \n",
    "            evaluator=None, \n",
    "            iterations=10, \n",
    "            initial_sample_size=10, \n",
    "            acquisition_size=10, \n",
    "            acquisition_method=\"greedy\", \n",
    "            retrain=True,\n",
    "            seeds=[]) -> None:\n",
    "        \"\"\"\n",
    "        Initializes a Modeller object with the provided parameters.\n",
    "        \"\"\"        \n",
    "        self.dataset = dataset.copy()\n",
    "        self.evaluator = evaluator\n",
    "        self.iterations = iterations\n",
    "        self.initial_sample_size = initial_sample_size\n",
    "        self.acquisition_size = acquisition_size\n",
    "        self.acquisition_method = acquisition_method\n",
    "        self.retrain = retrain\n",
    "        self.seeds = seeds\n",
    "        self.results = {}\n",
    "\n",
    "    def _initial_sampler(self):\n",
    "        \"\"\"\n",
    "        Randomly samples the initial points from the dataset.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Array of randomly selected points.\n",
    "        \"\"\"\n",
    "        random_points = self.dataset.get_samples(self.initial_sample_size, remove_points=True)\n",
    "\n",
    "        return random_points\n",
    "\n",
    "    def _acquisition(self, model):\n",
    "        \"\"\"\n",
    "        Performs the acquisition step to select new points for the model.\n",
    "\n",
    "        Parameters:\n",
    "            model: The model object used for acquisition.\n",
    "\n",
    "        Returns:\n",
    "            Dataset: The acquired dataset containing the selected points.\n",
    "        \"\"\"\n",
    "\n",
    "        # Predict on the full dataset\n",
    "        preds = model.predict(self.dataset.X)\n",
    "\n",
    "        if self.acquisition_method == \"greedy\":\n",
    "\n",
    "            # Find indices of the x-number of smallest values\n",
    "            indices = np.argpartition(preds, self.acquisition_size)[:self.acquisition_size]\n",
    "\n",
    "            # Get the best docked molecules from the dataset\n",
    "            acq_dataset = self.dataset.get_points(indices)\n",
    "\n",
    "            # Remove these datapoints from the dataset\n",
    "            self.dataset.remove_points(indices)\n",
    "\n",
    "        if self.acquisition_method == \"random\":\n",
    "            \n",
    "            # Get random points and delete from dataset\n",
    "            acq_dataset = self.dataset.get_samples(self.acquisition_size, remove_points=True)\n",
    "\n",
    "        return acq_dataset\n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fits the model to the data.\n",
    "        This method needs to be implemented in child classes.\n",
    "        \"\"\"        \n",
    "        pass\n",
    "\n",
    "    def predict():\n",
    "        \"\"\"\n",
    "        Generates predictions using the fitted model.\n",
    "        This method needs to be implemented in child classes.\n",
    "        \"\"\"        \n",
    "        pass\n",
    "\n",
    "    def save():\n",
    "        \"\"\"\n",
    "        Save the model\n",
    "        This method needs to be implemented in child classes.\n",
    "        \"\"\"         \n",
    "        pass\n",
    "\n",
    "    def load():\n",
    "        \"\"\"\n",
    "        Load the model\n",
    "        This method needs to be implemented in child classes.\n",
    "        \"\"\" \n",
    "        pass\n",
    "    \n",
    "    def call_evaluator(self, i):\n",
    "        \"\"\"\n",
    "        Calls the evaluator to evaluate the model's performance and stores the results.\n",
    "\n",
    "        Parameters:\n",
    "            i (int): The current iteration number.\n",
    "\n",
    "        \n",
    "        Notes: Should always be called when defining the fit() in a child model.\n",
    "        \"\"\"\n",
    "        results = self.evaluator.evaluate(self, self.dataset)\n",
    "        print(f\"Iteration {i+1}, Results: {results}\")\n",
    "\n",
    "        # Store results\n",
    "        self.results[i+1] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from MDRMF.models.modeller import Modeller\n",
    "from MDRMF.dataset import Dataset\n",
    "\n",
    "class RFModellerDev(ModellerDev):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataset, \n",
    "        evaluator=None, \n",
    "        iterations=10, \n",
    "        initial_sample_size=10, \n",
    "        acquisition_size=10, \n",
    "        acquisition_method=\"greedy\", \n",
    "        retrain=True,\n",
    "        seeds=[],\n",
    "        **kwargs) -> None:\n",
    "\n",
    "        super().__init__(\n",
    "            dataset, \n",
    "            evaluator, \n",
    "            iterations, \n",
    "            initial_sample_size, \n",
    "            acquisition_size, \n",
    "            acquisition_method, \n",
    "            retrain,\n",
    "            seeds\n",
    "            )\n",
    "\n",
    "        self.kwargs = kwargs\n",
    "        self.model = RandomForestRegressor(**self.kwargs)\n",
    "\n",
    "    def fit(self):\n",
    "        \n",
    "        # Get random points\n",
    "        if self.seeds == []:\n",
    "            initial_pts = self._initial_sampler()\n",
    "        \n",
    "        # If freeze_sample is not empty and it's a list of integers use this as starting points\n",
    "        elif self.seeds and isinstance(self.seeds, list) and all(isinstance(i, int) for i in self.seeds):\n",
    "\n",
    "            # Get the seeded points and remember to remove them from the dataset\n",
    "            initial_pts = self.dataset.get_points(self.seeds, remove_points=True)\n",
    "\n",
    "        else:\n",
    "            logging.error(\"Seeds failed. Seeds must be a list of integers like [5, 25, 600, 5000]\")\n",
    "        \n",
    "        print(f\"Using points {initial_pts.y} as starting point.\")\n",
    "        self.model.fit(initial_pts.X, initial_pts.y)\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "        # Acquire new points\n",
    "            acquired_pts = self._acquisition(self.model)\n",
    "\n",
    "            # Merge old and new points\n",
    "            if i == 0:\n",
    "                model_dataset = self.dataset.merge_datasets([initial_pts, acquired_pts])\n",
    "            else:\n",
    "                model_dataset = self.dataset.merge_datasets([model_dataset, acquired_pts])\n",
    "\n",
    "            if self.retrain:\n",
    "                # Reset model and train\n",
    "                self.model = RandomForestRegressor(**self.kwargs)\n",
    "                self.model.fit(model_dataset.X, model_dataset.y)\n",
    "            else:\n",
    "                # Train on existing model\n",
    "                self.model.fit(model_dataset.X, model_dataset.y)\n",
    "\n",
    "            if self.evaluator is not None:\n",
    "                self.call_evaluator(i=i)\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, dataset: Dataset):\n",
    "\n",
    "        if isinstance(dataset, Dataset):\n",
    "            return self.model.predict(dataset.X)\n",
    "        else:\n",
    "            logging.error(\"Wrong object type. Must be of type `Dataset`\")\n",
    "\n",
    "    def save(self, filename: str):\n",
    "        \"\"\"\n",
    "        Save the RFModeller to a pickle file\n",
    "        \"\"\"\n",
    "        # Check if filename is a string.\n",
    "        if not isinstance(filename, str):\n",
    "            raise ValueError(\"filename must be a string\")\n",
    "        \n",
    "        try:\n",
    "            with open(filename, \"wb\") as f:\n",
    "                pickle.dump(self, f)\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"File not found: {filename}\")\n",
    "            raise\n",
    "        except IOError as e:\n",
    "            logging.error(f\"IOError: {str(e)}\")\n",
    "            raise\n",
    "        except pickle.PicklingError as e:\n",
    "            logging.error(f\"Failed to pickle model: {str(e)}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def load(filename: str):\n",
    "        \n",
    "        # Check if filename is a string.\n",
    "        if not isinstance(filename, str):\n",
    "            raise ValueError(\"filename must be a string\")\n",
    "        \n",
    "        # Check if file exists.\n",
    "        if not os.path.isfile(filename):\n",
    "            raise FileNotFoundError(f\"No such file or directory: '{filename}'\")\n",
    "        \n",
    "        try:\n",
    "            with open(filename, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"File not found: {filename}\")\n",
    "            raise\n",
    "        except IOError as e:\n",
    "            logging.error(f\"IOError: {str(e)}\")\n",
    "            raise\n",
    "        except pickle.UnpicklingError as e:\n",
    "            logging.error(f\"Failed to unpickle model: {str(e)}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MDRMF.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load(\"dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dataset X.shape: (9898, 512), y.shape: (9898,), w.shape: (9898,), ids: ['C[C@@H](NC(=O)N1C[C@H](c2ccccc2)[C@H]2COCC[C@H]21)c1ccc(NC(=O)NC2CC2)cc1'\n",
       " 'O=C(Nc1cccc(C(=O)N2CCC(c3c[nH]c4ncccc34)CC2)c1)[C@@H]1Cc2ccccc2O1'\n",
       " 'Cc1nn(-c2ccccc2)c2nc(C(=O)N3CCC([C@H]4C(=O)Nc5ccccc54)CC3)ccc12' ...\n",
       " 'Cn1cccc(C(=O)N2CCN(C3CC3)c3ccc(Cl)cc32)c1=O'\n",
       " 'O=C([O-])[C@H]1CC[C@@H](C(=O)N2CCCc3ccccc32)CC1'\n",
       " 'CCNS(=O)(=O)c1cc(NCCOC)ccn1']>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_set = dataset.get_points([5, 8, 10, 100, 1000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.3322 , -12.0921 , -11.9436 , -10.7807 ,  -9.53808,  -7.9548 ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeg nåede at lave ModellerDev og RFModellerDev klar til at de kan acceptere en liste af prædefinerede punkter. Næste ting er at lave en RFModellerDev instance og se om jeg kan få den til at bruge en liste af punkter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MDRMF.evaluator import Evaluator\n",
    "from MDRMF import Model\n",
    "metrics = ['top-k']\n",
    "k_values = ['100']\n",
    "eval = Evaluator(dataset, metrics, k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RFModellerDev(\n",
    "    dataset=dataset,\n",
    "    evaluator=eval,\n",
    "    #seeds=[5, 5000, 5550, 6014, 3]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using points [-5.14831 -8.50507 -8.7673  -8.13574 -6.44748 -5.6686  -7.95792 -5.963\n",
      " -3.51802 -4.85851] as starting point.\n",
      "Iteration 1, Results: {'top-100': 0.02}\n",
      "Iteration 2, Results: {'top-100': 0.05}\n",
      "Iteration 3, Results: {'top-100': 0.03}\n",
      "Iteration 4, Results: {'top-100': 0.02}\n",
      "Iteration 5, Results: {'top-100': 0.03}\n",
      "Iteration 6, Results: {'top-100': 0.04}\n",
      "Iteration 7, Results: {'top-100': 0.03}\n",
      "Iteration 8, Results: {'top-100': 0.04}\n",
      "Iteration 9, Results: {'top-100': 0.04}\n",
      "Iteration 10, Results: {'top-100': 0.03}\n"
     ]
    }
   ],
   "source": [
    "model = Model(model=rf_model)\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
