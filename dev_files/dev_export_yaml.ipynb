{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "import inspect\n",
    "import time\n",
    "import shutil\n",
    "from typing import List\n",
    "from MDRMF.evaluator import Evaluator\n",
    "import MDRMF.models as mfm\n",
    "from MDRMF import Dataset, MoleculeLoader, Featurizer, Model\n",
    "\n",
    "class Experimenter:\n",
    "\n",
    "    def __init__(self, config_file: str):\n",
    "        self.config_file = config_file # use this line when developing/debugging in jupyter\n",
    "        #self.config_file = os.path.join(os.path.dirname(os.path.dirname(os.path.realpath(__file__))), config_file)\n",
    "        self.experiments = self._load_config()\n",
    "    \n",
    "    def _load_config(self) -> List[dict]:\n",
    "        with open(self.config_file, 'r') as stream:\n",
    "            try:\n",
    "                config = yaml.safe_load(stream)\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)\n",
    "                return []\n",
    "\n",
    "        # If there is only one experiment, make it into a list\n",
    "        if isinstance(config, dict):\n",
    "            config = [config]\n",
    "\n",
    "        return [config]\n",
    "    \n",
    "    def conduct_all_experiments(self):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        shutil.copy(self.config_file, 'settings.yaml')\n",
    "\n",
    "        for config in self.experiments:\n",
    "            for experiment in config:\n",
    "                key, value = list(experiment.items())[0]\n",
    "                if key == 'Experiment':\n",
    "                    self.conduct_experiment(value)\n",
    "                if key == 'Dataset':\n",
    "                    # Call self.make_dataset(value)\n",
    "                    pass\n",
    "                if key == 'Parallelize_experiments':\n",
    "                    # add code here to handle 'Parallelize_experiments' cases\n",
    "                    pass\n",
    "\n",
    "        def _format_time(seconds):\n",
    "\n",
    "            hours, remainder = divmod(seconds, 3600)\n",
    "            minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "            if hours:\n",
    "                time_str = \"{} hour(s), {} minute(s), {} second(s)\".format(int(hours), int(minutes), int(seconds))\n",
    "            elif minutes:\n",
    "                time_str = \"{} minute(s), {} second(s)\".format(int(minutes), int(seconds))\n",
    "            else:\n",
    "                time_str = \"{} second(s)\".format(int(seconds))\n",
    "\n",
    "            return time_str\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(\"Lab time over. All experiments conducted. Look for the results folder.\")\n",
    "        print(\"Time elapsed: \", _format_time(elapsed_time))\n",
    "    \n",
    "    def conduct_experiment(self, exp_config: dict):\n",
    "\n",
    "        # --- Data setup --- #\n",
    "        # If there is a dataset use this\n",
    "        if 'dataset' in exp_config:\n",
    "            dataset_file = exp_config['dataset']\n",
    "            dataset_model = Dataset.load(dataset_file)\n",
    "        elif 'data' in exp_config:\n",
    "            # Load data\n",
    "            data_conf = exp_config['data']\n",
    "\n",
    "            datafile = data_conf['datafile']\n",
    "            SMILES = data_conf['SMILES_col']\n",
    "            scores = data_conf['scores_col']\n",
    "            ids = data_conf['ids_col']\n",
    "\n",
    "            data = MoleculeLoader(datafile, SMILES, scores).df\n",
    "\n",
    "            # Featurize\n",
    "            feat = Featurizer(data)\n",
    "            feat_config = exp_config['featurizer']\n",
    "\n",
    "            feat_type = feat_config['name']\n",
    "            feat_params = feat_config.copy()\n",
    "            del feat_params['name']\n",
    "\n",
    "            features = feat.featurize(feat_type, **feat_params)\n",
    "\n",
    "            # Get data\n",
    "            X = features\n",
    "            y = data[scores]\n",
    "            ids_data = data[ids]\n",
    "\n",
    "            # Make datasets\n",
    "            dataset_model = Dataset(X=X, y=y, ids=ids_data)\n",
    "\n",
    "            # Save the dataset\n",
    "            dataset_model.save(\"dataset_\" + exp_config['name']+\".pkl\")\n",
    "\n",
    "        # --- Directory setup --- #\n",
    "        # Create main directory\n",
    "        experiment_directory = os.path.join(\"Experiment_Root\", exp_config['name'])\n",
    "        os.makedirs(experiment_directory, exist_ok=True)\n",
    "\n",
    "        # Save dataset\n",
    "        dataset_file = os.path.join(experiment_directory, \"dataset.pkl\")\n",
    "        dataset_model.save(dataset_file)\n",
    "\n",
    "        # Create models directory\n",
    "        models_directory = os.path.join(experiment_directory, \"models\")\n",
    "        os.makedirs(models_directory, exist_ok=True)\n",
    "        \n",
    "        # --- Model setup --- #\n",
    "        model_config = exp_config['model']\n",
    "        model_name = model_config['name']\n",
    "        model_params = model_config.copy()\n",
    "        del model_params['name']\n",
    "\n",
    "        # Check if model class exists\n",
    "        model_class = None\n",
    "        for name, obj in inspect.getmembers(mfm):\n",
    "            if inspect.isclass(obj) and name == model_name:\n",
    "                model_class = obj\n",
    "                break\n",
    "\n",
    "        if model_class is None:\n",
    "            raise ValueError(f\"Model {model_name} not found in MDRMF.models\")\n",
    "\n",
    "        # Setup evaluator\n",
    "        model_metrics = exp_config['metrics']\n",
    "        metrics = model_metrics['names']\n",
    "        k_values = model_metrics['k']\n",
    "        evaluator = Evaluator(dataset_model, metrics, k_values)\n",
    "\n",
    "        results_list = []\n",
    "\n",
    "        # --- Conduct replicate experiments and save results --- #\n",
    "        for i in range(exp_config['replicate']):\n",
    "            print(f\"Running Experiment {exp_config['name']} replicate {i+1}\")\n",
    "\n",
    "            # Setup model\n",
    "            model_input = model_class(dataset_model, evaluator=evaluator, **model_params)\n",
    "            model = Model(model=model_input)\n",
    "            model.train()\n",
    "            \n",
    "            # Save model\n",
    "            model_file = os.path.join(models_directory, f\"{model_name} Exp{i+1}.pkl\")\n",
    "            model.save(model_file)\n",
    "\n",
    "            # Add results to list\n",
    "            results = model.results\n",
    "            for rank, score_dict in results.items():\n",
    "                result_dict = {'replicate': i+1, 'rank': rank}\n",
    "                result_dict.update(score_dict)\n",
    "                results_list.append(result_dict)\n",
    "            \n",
    "        # Convert results to a DataFrame \n",
    "        results_df = pd.DataFrame(results_list)\n",
    "        results_df.to_csv(os.path.join(experiment_directory, \"results.csv\"), index=False)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import argparse\n",
    "#     import time\n",
    "\n",
    "#     parser = argparse.ArgumentParser(description='Conduct machine fishing experiments based on a YAML config file.')\n",
    "#     parser.add_argument('config_file', type=str, help='The path to the YAML configuration file.')\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     experimenter = Experimenter(args.config_file)\n",
    "#     experimenter.conduct_all_experiments()\n",
    "\n",
    "    # To run an experiment after `pip install MDRMF` do this in your command prompt.\n",
    "    # python -m MDRMF.experimenter config-file.yaml\n",
    "    # An example config file is found in an example folder (not created yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.yaml\", 'r') as stream:\n",
    "    try:\n",
    "        config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.yaml\", \"w\") as stream:\n",
    "    yaml.dump(config, stream, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output.yaml'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy(\"test.yaml\", \"output.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experimenter(\"test.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.yaml'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.config_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
