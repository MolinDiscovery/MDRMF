{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests of dataset method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from MDRMF import Dataset\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from collections import defaultdict\n",
    "from rdkit.Chem import rdFMCS\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xsj110\\AppData\\Local\\Temp\\ipykernel_19056\\1614015686.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['smiles'] = df_train['smiles'].apply(lambda x: mol2fp(Chem.MolFromSmiles(x)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/jensengroup/GB_GA/master/ZINC_250k.smi', header=None)\n",
    "\n",
    "def mol2fp(mol):\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)\n",
    "    arr = np.zeros((0,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr.astype(int)\n",
    "\n",
    "df.columns = ['smiles']\n",
    "\n",
    "df = df.head(100)\n",
    "df['logP'] = [Descriptors.MolLogP(Chem.MolFromSmiles(s)) for s in df['smiles']]\n",
    "\n",
    "df_train = df.head(10)\n",
    "df_train['smiles'] = df_train['smiles'].apply(lambda x: mol2fp(Chem.MolFromSmiles(x)))\n",
    "\n",
    "X = df_train['smiles']\n",
    "y = df_train['logP']\n",
    "\n",
    "dataset = Dataset(X, y, df_train.index)\n",
    "pairwise_dataset = dataset.create_pairwise_dataset()\n",
    "\n",
    "# rfr = RandomForestRegressor()\n",
    "# rfr.fit(dataset.X, dataset.y)\n",
    "\n",
    "rfr_pairwise = RandomForestRegressor()\n",
    "rfr_pairwise.fit(pairwise_dataset.X, pairwise_dataset.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.836891180000002 3.4174200000000017\n"
     ]
    }
   ],
   "source": [
    "mol = 11\n",
    "s = df['smiles'].iloc[mol]\n",
    "X_test = []\n",
    "for st in df_train['smiles']:\n",
    "    X = list(st) + list(mol2fp(Chem.MolFromSmiles(s))) + (list(st - mol2fp(Chem.MolFromSmiles(s))))\n",
    "    X_test.append(X)\n",
    "\n",
    "dy_preds = rfr_pairwise.predict(np.array(X_test))\n",
    "\n",
    "y_preds = df_train['logP'] + dy_preds\n",
    "y_pred = y_preds.mean()\n",
    "\n",
    "print(y_pred, df['logP'].iloc[mol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 \t 3.836891180000002 \t 3.4174200000000017\n",
      "12 \t 2.9589798800000016 \t 2.3794000000000004\n",
      "13 \t 3.017613160000002 \t 3.6157200000000023\n",
      "14 \t 3.828545380000002 \t 1.8117999999999994\n",
      "15 \t 3.675127240000002 \t 0.6130000000000004\n",
      "16 \t 2.9495092000000014 \t 4.2250400000000035\n",
      "17 \t 2.9715343200000017 \t 2.1622000000000003\n",
      "18 \t 2.536603820000001 \t 3.3920200000000023\n",
      "19 \t 2.7803263000000014 \t 3.803600000000002\n"
     ]
    }
   ],
   "source": [
    "mols_to_predict = slice(11, 20)\n",
    "smiles_to_predict = df['smiles'].iloc[mols_to_predict]\n",
    "\n",
    "c = 11\n",
    "for s in smiles_to_predict:\n",
    "    X_test = []\n",
    "    for st in df_train['smiles']:\n",
    "        X = list(st) + list(mol2fp(Chem.MolFromSmiles(s))) + (list(st - mol2fp(Chem.MolFromSmiles(s))))\n",
    "        X_test.append(X)\n",
    "\n",
    "    dy_preds = rfr_pairwise.predict(np.array(X_test))\n",
    "    y_preds = df_train['logP'] + dy_preds\n",
    "    y_pred = y_preds.mean()\n",
    "\n",
    "    print(c, \"\\t\", y_pred, \"\\t\", df['logP'].iloc[c])\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these results I confirmed that I got the same results as Jan did in his notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a dataset with rdkit2D(200 compounds) and docking scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_rdkit2d = Dataset.load('datasets/dataset_rdkit2d_200.pkl')\n",
    "\n",
    "train_points = [x for x in range(10)] # get the first 10 points\n",
    "test_points = [x for x in range(10, 20)] # get the next 10 points\n",
    "\n",
    "# Create training set\n",
    "dataset_rdkit2d_train = dataset_rdkit2d.get_samples(10)\n",
    "\n",
    "# Create test set\n",
    "dataset_rdkit2d_test = dataset_rdkit2d.get_samples(10)\n",
    "\n",
    "# Create pairwise set\n",
    "dataset_rdkit2d_pairwise = dataset_rdkit2d_train.create_pairwise_dataset()\n",
    "\n",
    "# Train model\n",
    "rfr_pairwise_rdkit2d = RandomForestRegressor()\n",
    "rfr_pairwise_rdkit2d.fit(dataset_rdkit2d_pairwise.X, dataset_rdkit2d_pairwise.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds \t trues\n",
      "-7.4 \t -7.1\n",
      "-6.3 \t -8.7\n",
      "-7.0 \t -7.0\n",
      "-6.5 \t -9.7\n",
      "-8.2 \t -3.7\n",
      "-7.0 \t -8.6\n",
      "-6.6 \t -9.4\n",
      "-6.7 \t -8.0\n",
      "-7.5 \t -7.0\n",
      "-7.0 \t -9.0\n",
      "Avg. diff: 1.8722305559999999\n"
     ]
    }
   ],
   "source": [
    "def predict(train_dataset: Dataset, predict_dataset: Dataset, model: RandomForestRegressor):\n",
    "\n",
    "    mols_predict = predict_dataset.X\n",
    "    mols_train = train_dataset.X\n",
    "    y_train = train_dataset.y\n",
    "\n",
    "    preds = []\n",
    "    for pmol in mols_predict:\n",
    "        X_test = []\n",
    "        for tmol in mols_train:\n",
    "            X = list(tmol) + list(pmol) + (list(tmol - pmol))\n",
    "            X_test.append(X)      \n",
    "        \n",
    "        dy_preds = model.predict(np.array(X_test))\n",
    "        y_preds = y_train + dy_preds\n",
    "        y_pred = y_preds.mean()\n",
    "        preds.append(y_pred)\n",
    "\n",
    "    return preds\n",
    "\n",
    "preds = predict(dataset_rdkit2d_train, dataset_rdkit2d_test, rfr_pairwise_rdkit2d)\n",
    "trues = dataset_rdkit2d_test.y\n",
    "\n",
    "print('preds', '\\t', 'trues')\n",
    "diffs = []\n",
    "for i, j in zip(preds, trues):\n",
    "    print(round(i, 1), '\\t', round(j, 1))\n",
    "    diff = abs(i-j)\n",
    "    diffs.append(diff)\n",
    "print('Avg. diff:', np.mean(diffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trying with morgan(512 bits) featurized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds \t trues\n",
      "-9.8 \t -8.5\n",
      "-8.7 \t -9.3\n",
      "-9.7 \t -9.3\n",
      "-9.6 \t -7.2\n",
      "-7.1 \t -6.2\n",
      "-9.7 \t -8.2\n",
      "-9.9 \t -7.6\n",
      "-6.1 \t -6.9\n",
      "-7.2 \t -9.4\n",
      "-9.9 \t -8.1\n",
      "Avg. diff: 1.442891432\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.load('datasets/dataset_morgan.pkl')\n",
    "dataset_morgan_train = dataset.get_samples(10)\n",
    "dataset_morgan_test = dataset.get_samples(10)\n",
    "\n",
    "dataset_morgan_pairwise = dataset_morgan_train.create_pairwise_dataset()\n",
    "rfr_pairwise_morgan = RandomForestRegressor()\n",
    "rfr_pairwise_morgan.fit(dataset_morgan_pairwise.X, dataset_morgan_pairwise.y)\n",
    "\n",
    "preds = predict(dataset_morgan_train, dataset_morgan_test, rfr_pairwise_morgan)\n",
    "trues = dataset_morgan_test.y\n",
    "\n",
    "print('preds', '\\t', 'trues')\n",
    "diffs = []\n",
    "for i, j in zip(preds, trues):\n",
    "    print(round(i, 1), '\\t', round(j, 1))\n",
    "    diff = abs(i-j)\n",
    "    diffs.append(diff)\n",
    "print('Avg. diff:', np.mean(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "It took 25.6 seconds to compute and fit the model with 50 mols in the training set.\n",
      "For 50 mols there is a 50^2 = 2500 combinations to be computed, fitted and predicted.\n",
      "For 150 mols there is 150^2 = 22500 combinations to be computed, fitted and predicted.\n",
      "This is a 9.0 fold increase meaning it should take 3.8 minutes to compute.\n",
      "In reality, however, it took 7.21 minutes, because fitting the model and predicting also takes up time.\n",
      "Additionally, and this probably makes up for the largest delta between the approx. 4 minutes and 7 minutes, is the exponential\n",
      "amount of combinations to be computed. Finally, memory shortage will become a problem for large datasets.\n",
      "\n",
      "In conclusion, using pairwise methods is heavy on computation and is very memory intensive for large datasets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 150 ** 2\n",
    "b = 50 ** 2\n",
    "c = a/b\n",
    "print(f'''\n",
    "It took 25.6 seconds to compute and fit the model with 50 mols in the training set.\n",
    "For 50 mols there is a 50^2 = {50 ** 2} combinations to be computed, fitted and predicted.\n",
    "For 150 mols there is 150^2 = {150 ** 2} combinations to be computed, fitted and predicted.\n",
    "This is a {c} fold increase meaning it should take {round(25.6*9/60, 1)} minutes to compute.\n",
    "In reality, however, it took 7.21 minutes, because fitting the model and predicting also takes up time.\n",
    "Additionally, and this probably makes up for the largest delta between the approx. 4 minutes and 7 minutes, is the exponential\n",
    "amount of combinations to be computed. Finally, memory shortage will become a problem for large datasets.\n",
    "\n",
    "In conclusion, using pairwise methods is heavy on computation and is very memory intensive for large datasets.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trying with CDDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds \t trues\n",
      "-10.1 \t -7.2\n",
      "-7.7 \t -5.0\n",
      "-9.8 \t -7.7\n",
      "-7.5 \t -8.6\n",
      "-9.5 \t -6.9\n",
      "-9.2 \t -7.2\n",
      "-7.8 \t -8.2\n",
      "-9.5 \t -9.2\n",
      "-7.4 \t -6.1\n",
      "-7.3 \t -8.6\n",
      "Avg. diff: 1.6657944633333333\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.load('datasets/dataset_CDDD.pkl')\n",
    "dataset_CDDD_train = dataset.get_samples(15)\n",
    "dataset_CDDD_test = dataset.get_samples(10)\n",
    "\n",
    "dataset_CDDD_pairwise = dataset_CDDD_train.create_pairwise_dataset()\n",
    "rfr_pairwise_CDDD = RandomForestRegressor()\n",
    "rfr_pairwise_CDDD.fit(dataset_CDDD_pairwise.X, dataset_CDDD_pairwise.y)\n",
    "\n",
    "preds = predict(dataset_CDDD_train, dataset_CDDD_test, rfr_pairwise_CDDD)\n",
    "trues = dataset_CDDD_test.y\n",
    "\n",
    "print('preds', '\\t', 'trues')\n",
    "diffs = []\n",
    "for i, j in zip(preds, trues):\n",
    "    print(round(i, 1), '\\t', round(j, 1))\n",
    "    diff = abs(i-j)\n",
    "    diffs.append(diff)\n",
    "print('Avg. diff:', np.mean(diffs))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final test\n",
    "##### Does the predict function work as expected compared to the original code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...\n",
      "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "2     [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3     [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "4     [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "                            ...                        \n",
      "95    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...\n",
      "96    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "97    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "98    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...\n",
      "99    [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "Name: smiles, Length: 100, dtype: object\n",
      "0     5.05060\n",
      "1     3.11370\n",
      "2     4.96778\n",
      "3     4.00022\n",
      "4     3.60956\n",
      "       ...   \n",
      "95    4.47690\n",
      "96    2.57252\n",
      "97    0.12710\n",
      "98    1.93192\n",
      "99    4.62630\n",
      "Name: logP, Length: 100, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# First create a dataset from the initial df as used in the beginning of the notebook.\n",
    "# Featurize the smiles and assign them to X.\n",
    "\n",
    "X_final = df['smiles'].apply(lambda x: mol2fp(Chem.MolFromSmiles(x)))\n",
    "print(X_final)\n",
    "y_final = df['logP']\n",
    "print(y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds \t trues\n",
      "3.7 \t 3.4\n",
      "2.8 \t 2.4\n",
      "3.0 \t 3.6\n",
      "3.7 \t 1.8\n",
      "3.5 \t 0.6\n",
      "3.0 \t 4.2\n",
      "3.0 \t 2.2\n",
      "2.5 \t 3.4\n",
      "2.7 \t 3.8\n",
      "Avg. diff: 1.1424055311111125\n"
     ]
    }
   ],
   "source": [
    "# Putting it all together in a dataset\n",
    "dataset_final = Dataset(X=X_final, y=y_final)\n",
    "\n",
    "# Creating training and test sets\n",
    "dataset_final_train = dataset_final.get_points([x for x in range(10)]) # First 10 points\n",
    "dataset_final_test = dataset_final.get_points([x for x in range (11,20)]) # Next 10 points\n",
    "\n",
    "# Creating pairwise dataset\n",
    "dataset_final_pairwise = dataset_final_train.create_pairwise_dataset()\n",
    "\n",
    "# Create and train the model\n",
    "rfr_pairwise_final = RandomForestRegressor()\n",
    "rfr_pairwise_final.fit(dataset_final_pairwise.X, dataset_final_pairwise.y)\n",
    "\n",
    "preds = predict(dataset_final_train, dataset_final_test, rfr_pairwise_final)\n",
    "trues = dataset_final_test.y\n",
    "\n",
    "print('preds', '\\t', 'trues')\n",
    "diffs = []\n",
    "for i, j in zip(preds, trues):\n",
    "    print(round(i, 1), '\\t', round(j, 1))\n",
    "    diff = abs(i-j)\n",
    "    diffs.append(diff)\n",
    "print('Avg. diff:', np.mean(diffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Final code      Initial code\n",
    "\n",
    "preds \t trues  preds                   trues\n",
    "3.7 \t 3.4    3.836891180000002 \t    3.4174200000000017\n",
    "2.8 \t 2.4    2.9589798800000016 \t    2.3794000000000004\n",
    "3.0 \t 3.6    3.017613160000002 \t    3.6157200000000023\n",
    "3.7 \t 1.8    3.828545380000002 \t    1.8117999999999994\n",
    "3.5 \t 0.6    3.675127240000002 \t    0.6130000000000004\n",
    "3.0 \t 4.2    2.9495092000000014 \t    4.2250400000000035\n",
    "3.0 \t 2.2    2.9715343200000017 \t    2.1622000000000003\n",
    "2.5 \t 3.4    2.536603820000001 \t    3.3920200000000023\n",
    "2.7 \t 3.8    2.7803263000000014 \t    3.803600000000002\n",
    "```\n",
    "### Conclusion\n",
    "The predict function work as expected\n",
    "Small variation occurs due to randomness in RFR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
